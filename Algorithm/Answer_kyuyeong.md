## 1. 동적 계획법(DP)에 대해 설명해주세요. (유지연)
**`동적 계획법`** 이란, 주어진 문제를 **작은 부분 문제**로 쪼개 **그들의 해**를 구하고 **저장**한 뒤, 이들을 **이용**해 **더 큰 크기의 부분문제를 해결**하므로써 주어진 문제를 해결하는 알고리즘 설계 기법을 얘기합니다.  
그리디 알고리즘과 마찬가지로 **최대/최소 경우 구하기**와 같이 **`최적화 문제`** 를 해결하거나, **`경우의 수`** 를 구해야 하는 문제를 푸는데 효과적인 기법입니다.  
동적 계획법을 적용하기 위해서는 문제가 `중복 부분문제 구조형태`를 띄어 **`순환`적인 성질**을 갖고있어 *이전에 계산한 작은 문제의 해*가 **다른 곳에서 필요**해야합니다. 또한, `최적 부분문제 구조 형태`를 띄어 *부분 문제들의 최적의 해*를 **이용**해 **본 문제의 최적의 해**를 구할 수 있어야 합니다.  
**점화식**과 **메모이제이션**을 활용해 **상향식**으로 문제를 풀거나, **재귀**와 **메모이제이션**을 활용해 **하향식**으로 문제를 풀 수 있습니다.  
*부분 문제들이 연관이 없어도 문제를 풀 수 있는* **분할 정복**과 달리, `동적 계획법`은 *부분 문제간 연관이 없으면* **적용이 불가능**합니다. 즉, 동적 계획법은 부분 문제 간 의존적 관계가 존재합니다.  
동적 계획법을 사용하는 **대표적인 문제**로는 `최장 공통 부분수열(LCS)`, `피보나치 수열`, `배낭 문제` 등이 있습니다.  
- [Dynamic Programming - GeeksforGeeks](https://www.geeksforgeeks.org/dynamic-programming/)
## 2. 재귀 알고리즘과 사용되는 사례에 대해 설명해주세요. (유지연)
**`재귀`** 란 주어진 문제의 해를 구하기 위해 ***동일하면서*** **더 작은 문제의 해**를 이용하는 `분할 정복` 방식의 한 종류입니다.  
**`재귀 함수`** 는 함수가 **직/간접적으로 자신을 호출**하는 형태를 말하며, 함수가 현재 처리할 수 있는 문제를 처리하는 **`기저 부분(basis part)`** 과, 더 작은 단위의 문제로 남은 작업을 떠넘기는 **`유도 부분(inductive part)`** 로 구성됩니다.  
**복잡한 문제**를 쪼개어 **단순화** 하여 풀 수 있고, 반복 코드보다 **코드 가독성이 높다**는 장점이 있습니다. 다만 반복 방식보다 **메모리, 성능 측면에서 효율성이 떨어질 수 있고**, 재귀 깊이가 너무 깊으면 **함수 스택 오버플로우가 발생**할 수 있습니다.  
재귀 알고리즘이 사용되는 사례로는 `하노이 타워`, `전위/중위/후위 트리 순회`, `DFS` 등이 있습니다.  
- [What is Recursion? - GeeksforGeeks](https://www.geeksforgeeks.org/what-is-recursion/)
## 3. 최단거리 알고리즘에 대해 설명해주세요. (유지연)
두 정점 사이의 경로 중 *간선 가중치의 합이 최소*인 `최단경로`를 구하기 위한 알고리즘으로는 **`다익스트라`**, **`벨만-포드`**, **`플로이드-워셜`**, **`A* 알고리즘`** 이 있습니다.  
**`다익스트라 알고리즘`** 은 시작 정점에서 다른 모든 정점으로의 최단 경로를 구하는 알고리즘으로, 시작 정점에서 **거리가 최소인 정점**을 선택하고 해당 정점을 경유지로 해 비용을 비교 갱신하는 과정을 반복해 최단 경로를 구하는 Greedy한 방식입니다.  
이론적으로 시간 복잡도는 $O(V^2)$ 이나, PQ를 사용하게되면 $O(V+ElogV)$의 시간복잡도를 보입니다.  
**`벨만-포드 알고리즘`** 은 **음의 가중치가 존재하는 그래프**(단, 음의 사이클은 발생하지 않음)에서 하나의 정점에서 목표 정점까지의 최단 경로를 구하는 알고리즘입니다.  
각 정점에 도달하는 최소 비용 배열을 만들고, V-1번 모든 간선들을 검토하며 **최소 비용 배열을 갱신**합니다. 이후, **음의 사이클이 존재하는지 확인**하기 위해 V번째로 한 번 더 간선을 검토해 비용이 더 줄어든 게 있는지 확인합니다. 만약 줄어들었다면 음의 사이클이 존재하는 것입니다. V번 만큼 E개의 간선들을 반복하므로 시간 복잡도는 평균적으로 $O(V*E)$를 가집니다.  
**`플로이드-워셜 알고리즘`** 은 *경유 가능한 정점을 하나씩 추가*하여 **모든 경유 가능한 정점들을 고려**해 **모든 쌍의 최단경로 거리**를 계산하는 방식입니다.  
모든 경로 쌍에 대해 각 정점을 경유지로 고려하기 때문에 $O(N^3)$의 시간 복잡도를 가집니다.  
- [Understanding Time Complexity Calculation for Dijkstra Algorithm | Baeldung on Computer Science](https://www.baeldung.com/cs/dijkstra-time-complexity)
- [Bellman–Ford Algorithm - GeeksforGeeks](https://www.geeksforgeeks.org/bellman-ford-algorithm-dp-23/)
## 4. 빅오표기법에 대해 설명해주세요. (특징, 성능 순서 등) (김은솔)
**`빅오(Big-O) 표기법`** 이란, 컴퓨터 과학에서 *입력의 크기가 커짐에 따라* **알고리즘의 시간 복잡도 또는 공간 복잡도**가 어떻게 **증가하는지 표현**하는데 사용되는 `점근 표기법`의 일종을 말합니다.  
**입력값의 크기에 따른 함수의 증가 정도**를 나타내기 위해 *중요하지 않은 저차항과 상수항을 **제거***한 뒤, **최고차항**만 남겨 해당 함수의 **점근적 상한**을 나타냅니다. 따라서, 알고리즘이 **해당 차수거나 더 낮은 차수의 시간 복잡도**를 가진다는 것을 알 수 있습니다.  
예시로 $O(N^2)$인 함수가 있다면, 해당 함수는 아무리 오래걸려도 $N^2$번 이하의 작업을 수행한다고 짐작할 수 있습니다. 이 때문에 `빅오 표기법`은 알고리즘의 **최악의 경우** 시간 복잡도를 나타내는 것으로 이해할 수 있습니다.  
알고리즘의 **점근적인 복잡도를 쉽게 측정**할 수 있다는 장점이 있지만, 실행 시간을 **근사치로 계산**하고, **최악의 경우만 고려**하기 때문에 알고리즘 **실행 시간을 과대평가**하는 경항이 있다는 한계가 존재합니다.  
일반적으로 팩토리얼( $O(N!)$ ), 지수의 거듭제곱( $O(3^n)$ , $O(2^n)$ , ...), 다항식( $O(n^3)$ ,  $O(n^2)$ , ... ), 로그( $O(log(n))$ ), 지수( $O(1)$ ) 순서대로 복잡도가 감소합니다.  
- [What is Big O Notation Explained: Space and Time Complexity (freecodecamp.org)](https://www.freecodecamp.org/news/big-o-notation-why-it-matters-and-why-it-doesnt-1674cfa8a23c/)
- [Big O notation - Wikipedia](https://en.wikipedia.org/wiki/Big_O_notation)
- [Big O Notation Tutorial - A Guide to Big O Analysis - GeeksforGeeks](https://www.geeksforgeeks.org/analysis-algorithms-big-o-analysis/#what-is-bigo-notation)
- [Bellman Ford Shortest Path Algorithm | Baeldung on Computer Science](https://www.baeldung.com/cs/bellman-ford)
- [lecture14.pdf (stanford.edu)](https://web.stanford.edu/class/archive/cs/cs161/cs161.1168/lecture14.pdf)
## 5. 선택정렬에 대해 설명해주세요. (김은솔)
**`선택정렬`** 이란 별도의 저장공간이 거의 필요하지 않은 `제자리 정렬`의 일종입니다.
오름차순 정렬의 경우, 먼저 주어진 배열에서 **가장 작은 값**을 찾은 뒤, 해당 요소를 **맨 앞의 값과 교체**합니다. 이후 *맨 앞 위치를 뺀* **나머지 배열에 대해 같은 작업**을 **반복**합니다.  
*배열 내 최소값이 어딨는지 알 수 없기 때문*에 **모두 탐색**해보아야 하고, 따라서 $N(N-1) \over 2$ 번 비교 작업을 수행하기 때문에 시간 복잡도는 최선, 평균, 최악의 경우 모두 $O(N^2)$을 갖습니다.  
## 6. 이진탐색에 대해 설명해주세요. (김은솔)
**`이진 탐색`** 이란 `정렬된 배열`에서 **조건을 만족하는 값을 검색**하기 위해 범위를 반복적으로 반으로 나누는 `검색 알고리즘`을 말합니다. **배열이 정렬되어있다는 정보를 활용**해, **범위를 반으로 나눠나가며 탐색**하기 때문에 $O(logN)$의 시간 복잡도를 갖게 됩니다.  
먼저 검색 범위의 **중간 요소를 기준이 되는 키**와 **비교**합니다. 동일하다면 탐색이 끝나고, 그렇지 않다면 탐색 범위를 좁혀 다시 탐색하게 됩니다.  
오름차순으로 정렬된 경우, 키가 **중간 요소보다 작다면** `왼쪽 절반`이, **중간 요소보다 크다면** `오른쪽 절반`을 범위로 다음 검색을 이어나갑니다. 이는 `재귀` 또는 `반복문` 형태로 구현할 수 있습니다.  
*배열의 크기가 클수록* **선형 탐색보다 빠르다**는 장점이 있지만, **요소들이 정렬되어 있어야** 하며 원소들이 **비교 가능한 자료형** 이어야 사용할 수 있습니다.  
이와 *유사한 형태*로, 정답이 될 수 있는 값이 연속적으로 놓여있는 경우 범위를 좁혀가며 정답이 될 수 있는 값을 찾는 `결정 문제`에 사용되는 **`파라메트릭 서치`** 라는 알고리즘도 있습니다.
## 7. 스위핑 알고리즘에 대해 설명해주세요. (박규영)
**`스위핑`** 알고리즘이란, 평면 또는 축 위에 나타나있는 왼쪽 점, 오른쪽 점 쌍으로 이뤄진 N개의 **선분들**에 대해 **한 방향(주로 왼쪽에서 오른쪽)** 으로 **탐색**하며 문제를 해결해나가는 방식을 뜻합니다.  
주어진 세그먼트의 **교차점 개수 구하기**, 가장 **가까운 점의 쌍 찾기**와 같은 문제에 사용되며, *일반적인 접근 방식*이 비교 가능한 모든 선분들끼리 계산해 $O(N^2)$의 시간복잡도를 갖는 반면, `스위핑` 방식은 정렬 후 한 방향으로 **선형 탐색을 진행**하기 때문에 $O(Nlog(N))$의 시간 복잡도를 갖습니다.  
- [Line Sweep Algorithm - Scaler Topics](https://www.scaler.com/topics/data-structures/line-sweep-algorithm/)
- [Maximum number of intersections possible for any of the N given segments - GeeksforGeeks](https://www.geeksforgeeks.org/maximum-number-of-intersections-possible-for-any-of-the-n-given-segments/?ref=header_search)

## 8. KMP 알고리즘에 대해 설명해주세요. (박규영)
**`KMP(Knuth-Morris-Pratt)`** 알고리즘이란 **본문 안**에서 *`패턴 문자열`을 찾는* **문자열 패턴 매칭**에 사용되는 알고리즘으로, **전처리**를 통해 패턴 문자열 길이 N의 크기를 갖는 `부분 일치 테이블`을 만들어 활용하는 방법을 말합니다.  
`부분일치 테이블`에는 *각 인덱스까지*의 **부분 문자열**에서 **접두사와 접미사가 동일한 부분 길이**를 저장합니다.  
- 즉 aba라는 문자가 있다면 테이블의 2번 인덱스에는 1이 저장되어있습니다.  

이후 `본문 포인터`와 `패턴 포인터`를 전진하며, 만약 둘의 **문자 불일치가 발생**한다면 패턴 포인터 `j`를 테이블의 `j-1`에 기록된 값으로 **이동**(즉, `j = arr[j-1]`)시키고, **계속 진행해**나가게 됩니다.  
비교할 문자 둘의 길이 `M`, `N`에 대해 시간복잡도 $O(M+N)$을 가져, $O(MN)$의 시간복잡도를 갖는 **브루트 포스 방식보다 효율적**입니다.  
## 9. 위상 정렬에 대해 설명해주세요. (박규영)
**`위상 정렬`** 이란, `유향 그래프`에서 **정점들**을 *간선의 방향을 거스르지 않도록* **나열**하는 것을 말합니다. 주로 **순서가 정해져 있는 작업들을 차례대로 수행**해야할 때, **순서를 정해주는데 사용**하는 알고리즘입니다.  
정렬의 순서는 `유향 그래프 구조`에 따라 **여러 개**의 종류로 나타날 수 있으며, 위상 정렬이 성립하기 위해서는 **그래프 내에 순환이 존재하지 않아야** 합니다. 즉, **`비순환 유향 그래프`** 에만 적용할 수 있는 알고리즘입니다.  
**`BFS 방식`** 의 경우, 먼저 **각 노드별 진입 차수**를 **배열에 기록**해놓고 **진입차수가 0인 노드부터 탐색**을 시작합니다. 이후 **인접한 노드들**을 탐색하며 **진입 차수를 감소**시키고, 진입 차수가 0이 된 노드를 **이어서 탐색**합니다. 각 노드를 **처음 방문**할 때 **리스트에 push**하게 되면 탐색이 끝난 후 해당 리스트가 **위상 정렬의 결과**가 됩니다.  
**`DFS 방식`** 의 경우 **`방문 배열`을 이용**하는데, 모든 정점을 순회하며 **방문하지 않은 정점**에 대해 **DFS를 수행**합니다. 이때 각 정점마다 **`방문하지 않은 인접 정점`들을 모두 탐색**한 뒤, **`현재 정점`을 `스택`에 저장**합니다. **DFS 순회 결과의 역순**이 **위상 정렬**과 **동일**하기 때문에, 모든 탐색 후 **스택에서 꺼낸 순서대로 정점을 나열**하면 **위상 정렬 순서**가 됩니다.  
## 10. BFS와 DFS에 대해 설명해주세요. (송채은)
**`BFS`** , 즉 **`너비 우선 탐색`** 은 `비선형 자료구조`를 `탐색`하는 알고리즘으로, 루트 노드에서 **자식 노드들을 차례대로 방문**한 뒤, 방문한 자식 노드들을 기준으로 하여 **해당 노드의 자식들을 차례대로 방문**하는 방식으로 진행됩니다.  
여기서 말하는 **`너비`** 는 *루트 노드로부터* **해당 노드까지 몇 개의 간선을 이동**해야 하는지를 의미하며, `BFS`는 이러한 `너비`를 점차 늘려가며 `너비`가 낮은 순서 부터 높은 순서까지 **순차적으로 탐색**합니다. 인접한 노드 탐색 후, 차례대로 다시 자식들을 탐색하므로 *`선입선출` 형태의 자료구조* `Queue`를 사용합니다.  
깊이가 깊지 않은, 즉 **규모가 작은 탐색**에 적합하며 주로 최단거리(접근단계가 최소인)를 찾는 문제에서 사용됩니다.  
**`DFS`** , 즉 **`깊이 우선 탐색`** 역시 비선형 자료구조를 탐색하는 알고리즘으로, 루트 노드부터 출발해, **한 방향으로 `갈 수 있는 경로`까지 탐색**한 뒤, 마지막으로 만난 **갈림길**이 있는 노드로 돌아와 **다른 방향의 노드로 탐색**하는 방식을 계속 반복해 모든 노드를 순회할 때 까지 진행됩니다.  
**가장 마지막에 만난 갈림길**로 되돌아가야 하기 때문에 *`후입선출` 형태의 자료구조* `Stack`을 사용합니다. 또한 현재 노드의 자식을 탐색하는 `기저 부분`과, 자식들의 자식을 탐색하는 `유도 부분`을 가진 **재귀 형태**로도 처리할 수 있습니다.  
주로 재귀 **함수로 구현한다는 특성**을 살릴 수 있는, 즉 **매개변수로 무언가 기록**해야 하는 문제에 적합합니다. 주로 이때까지의 경로의 특성을 저장해 **경로를 기록**하거나, **사이클 여부**를 따져야 하는 문제에서 사용됩니다.  
## 11. Prim과 Kruskal 알고리즘에 대해 설명해주세요. (송채은)
**`Prim`** 과 **`Kruskal`** 모두 `최소 신장 트리`, 즉 **N개의 정점**과 **N-1개의 간선**으로 이루어진 트리 중 **간선의 가중치 합이 최소**가 되는 경우를 구하기 위한 알고리즘을 말합니다. 두 방식 모두 `그리디`한 방법이며, `Prim`의 경우 **정점 중심**, `Kruskal`의 경우 **간선 중심**의 알고리즘이라는 차이가 있습니다.  
`Prim` 알고리즘의 경우 한 정점에서 **연결된 간선들 중 하나씩 선택**하며 최소 신장 트리를 만드는 방식을 말합니다. 임의의 정점에서 시작해 인접한 정점 중 최소 비용의 간선이 존재하는 정점을 선택하고, 이후 해당 정점에서 이러한 방식을 이어나가며 모든 정점을 방문할 때 까지 진행됩니다. *어떤 자료형을 사용하느냐*에 따라 시간 복잡도가 다른데, `인접 리스트`를 쓸 경우 $O(V^2 + E)$, `인접 행렬`의 경우 $O(2V^2)$으로 완전 그래프에 가깝지 않은 한 인접 리스트로 구현하는게 유리합니다. 추가로 `우선순위 큐`를 사용하면 $O((V+E) log V)$의 시간 복잡도를 갖습니다.  
`Kruskal` 알고리즘은 **간선**을 **가중치 오름차순으로 정렬**한 뒤, 가중치가 **낮은 간선부터 선택**하되 **사이클이 형성되지 않는 간선들만 선택**하며 최소 신장 트리를 만드는 방식을 말합니다. 그리고, 간선을 선택했을 때 사이클이 발생하는지 확인하기 위해 `Union-Find`를 사용합니다. `정렬` 또는 `우선순위 큐`의 사용이 필요해 $O(E log E)$의 시간 복잡도를 갖습니다. 
- [Time and Space Complexity Analysis of Kruskal Algorithm - GeeksforGeeks](https://www.geeksforgeeks.org/time-and-space-complexity-analysis-of-kruskal-algorithm/)
## 12. 알고 있는 정렬 알고리즘에 대해 설명해주시고 비교해서 어떤 차이가 있는지 설명해주세요. (송채은)
**`버블 소트`**, **`퀵 소트`**, **`셀렉션 소트`**, **`머지 소트`** 에 대해 설명드리겠습니다.
**`버블 소트`** 는 배열 내 원소를 반복적으로 탐색하면서, **`인접한 원소 쌍`** 을 **비교**하고 순서를 바꿔야 한다면 **교체**하는 방식의 정렬 알고리즘입니다. 이는 **배열이 완전히 정렬될 때 까지 반복**합니다. *배열 내 가장 작은 원소가 마지막 위치*에 있는 최악의 경우나 평균의 경우 $O(n^2)$의 시간 복잡도를, 이미 정렬된 최상의 경우 $O(n)$의 시간 복잡도를 갖습니다.  
**`퀵 소트`** 는 배열에서 한 `요소(pivot)`를 선택해 해당 요소보다 **작은 원소**를 **왼쪽**에, **큰 원소**를 **오른쪽**으로 옮긴 뒤, 피벗을 제외한 왼쪽 / 오른쪽 리스트들을 **다시 반복해 정렬**해나가는 방식의 정렬 알고리즘입니다. 이미 *정렬된 배열에서 pivot을 배열 내 최솟값*을 고르거나, *역정렬된 배열에서 배열 내 최댓값*을 선택하거나, *모든 원소가 똑같은* 최악의 경우 $O(n^2)$의 시간복잡도를, 평균의 경우 $O(nlog(n))$의 시간 복잡도를 갖습니다.  
**`셀렉션 소트`** 는 `배열 내 최솟값`을 찾고, 해당 원소를 **맨 앞의 값과 교체**합니다. 이후 *맨 앞 위치를 뺀* **나머지 배열**에서 **작업을 반복**해나가는 방식의 정렬 알고리즘입니다. 최선/평균/최악의 경우 모두 *범위 내 최솟값 위치를 알 수 없기 때문에* **모두 탐색**해봐야 해서 $O(n^2)$의 시간 복잡도를 갖습니다.  
**`머지 소트`** 는 정렬되지 않은 배열을 n개의 **하위 배열로 분할**한 뒤, 반복적으로 **하위 배열들**을 **병합하며 정렬**해나가는 방식의 정렬 알고리즘입니다. 최선/평균/최악의 경우 모두 $O(nlog(n))$ 의 시간 복잡도를 갖습니다.  